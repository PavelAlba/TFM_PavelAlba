{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels_df = pd.read_csv('/content/dengue_labels_train.csv')\n",
        "features_df = pd.read_csv('/content/dengue_features_train.csv')\n",
        "\n",
        "merged_df = pd.merge(features_df, labels_df, on=['city', 'year', 'weekofyear'], how='inner')\n",
        "\n",
        "filtered_df = merged_df[(merged_df['year'] >= 2001) & (merged_df['year'] <= 2008)]\n",
        "\n",
        "\n",
        "missing_values = filtered_df.isnull().sum()\n",
        "\n",
        "print(missing_values[missing_values > 0])\n"
      ],
      "metadata": {
        "id": "LqDK64K0M6ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ndvi_columns = ['ndvi_ne', 'ndvi_nw', 'ndvi_se', 'ndvi_sw']\n",
        "\n",
        "filtered_df[ndvi_columns] = filtered_df[ndvi_columns].apply(\n",
        "    lambda row: row.fillna(row.mean()), axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "4rifauzyOcXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "missing_values = filtered_df.isnull().sum()\n",
        "\n",
        "\n",
        "print(missing_values[missing_values > 0])"
      ],
      "metadata": {
        "id": "ZIfESUP8OjKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filtered_df = filtered_df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
        "\n",
        "\n",
        "missing_values_after_interpolation = filtered_df.isnull().sum()\n",
        "\n",
        "\n",
        "print(missing_values_after_interpolation)"
      ],
      "metadata": {
        "id": "l9NDH55uOyE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import (\n",
        "    ShuffleSplit,\n",
        "    KFold,\n",
        "    LeaveOneOut\n",
        ")\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "\n",
        "def cap_outliers(df, lower_percentile=0.05, upper_percentile=0.95):\n",
        "    capped_df = df.copy()\n",
        "    for column in capped_df.select_dtypes(include='number').columns:\n",
        "        lower_cap = capped_df[column].quantile(lower_percentile)\n",
        "        upper_cap = capped_df[column].quantile(upper_percentile)\n",
        "        capped_df[column] = np.where(capped_df[column] < lower_cap, lower_cap, capped_df[column])\n",
        "        capped_df[column] = np.where(capped_df[column] > upper_cap, upper_cap, capped_df[column])\n",
        "    return capped_df\n",
        "\n",
        "capped_df = cap_outliers(filtered_df)\n",
        "\n",
        "df = capped_df.copy()\n",
        "\n",
        "\n",
        "df['city_binary'] = df['city'].map({'sj': 0, 'iq': 1})\n",
        "\n",
        "\n",
        "df['sin_week'] = np.sin(2 * np.pi * df['weekofyear'] / 52)\n",
        "df['cos_week'] = np.cos(2 * np.pi * df['weekofyear'] / 52)\n",
        "\n",
        "\n",
        "columns_to_exclude = ['city', 'total_cases', 'year', 'weekofyear', 'week_start_date']\n",
        "X = df.drop(columns=columns_to_exclude, errors='ignore')\n",
        "y = df['total_cases']\n",
        "years = df['year']\n",
        "\n",
        "train_mask = years < (years.max())\n",
        "test_mask = years >= (years.max())\n",
        "X_train = X[train_mask].reset_index(drop=True)\n",
        "y_train = y[train_mask].reset_index(drop=True)\n",
        "X_test = X[test_mask].reset_index(drop=True)\n",
        "y_test = y[test_mask].reset_index(drop=True)\n",
        "years_train = years[train_mask].reset_index(drop=True)\n",
        "\n",
        "\n",
        "pipeline = make_pipeline(StandardScaler(), PLSRegression(n_components=8))\n",
        "\n",
        "\n",
        "validation_results = {}\n",
        "\n",
        "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    numerator = np.abs(y_true - y_pred)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    epsilon = 1e-10\n",
        "    denominator = np.where(denominator == 0, epsilon, denominator)\n",
        "    return np.mean(numerator / denominator) * 100\n",
        "\n",
        "\n",
        "def compute_metrics(model, X, y, cv, compute_r2=True):\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "    smape_scores = []\n",
        "    if compute_r2:\n",
        "        r2_scores = []\n",
        "\n",
        "    for train_index, val_index in cv.split(X):\n",
        "        X_train_cv, X_val_cv = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        model.fit(X_train_cv, y_train_cv)\n",
        "        y_pred_cv = model.predict(X_val_cv)\n",
        "\n",
        "        mae_scores.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
        "        rmse_scores.append(\n",
        "            np.sqrt(mean_squared_error(y_val_cv, y_pred_cv))\n",
        "        )\n",
        "        smape_scores.append(\n",
        "            symmetric_mean_absolute_percentage_error(y_val_cv, y_pred_cv)\n",
        "        )\n",
        "        if compute_r2:\n",
        "            r2_scores.append(r2_score(y_val_cv, y_pred_cv))\n",
        "\n",
        "    metrics = {\n",
        "        'MAE': np.mean(mae_scores),\n",
        "        'RMSE': np.mean(rmse_scores),\n",
        "        'SMAPE': np.mean(smape_scores)\n",
        "    }\n",
        "    if compute_r2:\n",
        "        metrics['R2'] = np.mean(r2_scores)\n",
        "    return metrics\n",
        "\n",
        "# 1. Random Cross-Validation (ShuffleSplit with 5 splits)\n",
        "random_cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        "scores = compute_metrics(pipeline, X_train, y_train, random_cv)\n",
        "validation_results['Random CV (5 splits)'] = scores\n",
        "\n",
        "# Random Cross-Validation (ShuffleSplit with 10 splits)\n",
        "random_cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
        "scores = compute_metrics(pipeline, X_train, y_train, random_cv)\n",
        "validation_results['Random CV (10 splits)'] = scores\n",
        "\n",
        "# 2. K-Fold Cross-Validation with various folds (Shuffled)\n",
        "for n_splits in [5, 7, 10]:\n",
        "    kfold_shuffle_cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    scores = compute_metrics(pipeline, X_train, y_train, kfold_shuffle_cv)\n",
        "    validation_results[f'K-Fold ({n_splits} folds, shuffled)'] = scores\n",
        "\n",
        "# 3. Leave-One-Out Cross-Validation (LOO)\n",
        "loo_cv = LeaveOneOut()\n",
        "scores = compute_metrics(pipeline, X_train, y_train, loo_cv, compute_r2=False)\n",
        "validation_results['Leave-One-Out'] = scores\n",
        "\n",
        "# 4. Venetian Blinds Cross-Validation\n",
        "num_partitions = 10\n",
        "indices = np.arange(len(X_train))\n",
        "venetian_mae_scores = []\n",
        "venetian_rmse_scores = []\n",
        "venetian_smape_scores = []\n",
        "venetian_r2_scores = []\n",
        "\n",
        "for i in range(num_partitions):\n",
        "    test_mask_vb = indices % num_partitions == i\n",
        "    train_mask_vb = ~test_mask_vb\n",
        "\n",
        "    X_train_vb = X_train.iloc[train_mask_vb]\n",
        "    X_val_vb = X_train.iloc[test_mask_vb]\n",
        "    y_train_vb = y_train.iloc[train_mask_vb]\n",
        "    y_val_vb = y_train.iloc[test_mask_vb]\n",
        "\n",
        "    pipeline.fit(X_train_vb, y_train_vb)\n",
        "    y_pred_vb = pipeline.predict(X_val_vb)\n",
        "\n",
        "    venetian_mae_scores.append(mean_absolute_error(y_val_vb, y_pred_vb))\n",
        "    venetian_rmse_scores.append(\n",
        "        np.sqrt(mean_squared_error(y_val_vb, y_pred_vb))\n",
        "    )\n",
        "    venetian_smape_scores.append(\n",
        "        symmetric_mean_absolute_percentage_error(y_val_vb, y_pred_vb)\n",
        "    )\n",
        "    venetian_r2_scores.append(r2_score(y_val_vb, y_pred_vb))\n",
        "\n",
        "validation_results['Venetian Blinds'] = {\n",
        "    'MAE': np.mean(venetian_mae_scores),\n",
        "    'RMSE': np.mean(venetian_rmse_scores),\n",
        "    'SMAPE': np.mean(venetian_smape_scores),\n",
        "    'R2': np.mean(venetian_r2_scores)\n",
        "}\n",
        "\n",
        "# 5. K-Fold Cross-Validation with 7 Folds (No Shuffling)\n",
        "kfold_cv = KFold(n_splits=7, shuffle=False)\n",
        "scores = compute_metrics(pipeline, X_train, y_train, kfold_cv)\n",
        "validation_results['K-Fold (7 folds, no shuffle)'] = scores\n",
        "\n",
        "# 6. Leave-One-Year-Out Cross-Validation (if 'year' column exists)\n",
        "if years is not None:\n",
        "    unique_years = sorted(years_train.unique())\n",
        "\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "    smape_scores = []\n",
        "    r2_scores = []\n",
        "\n",
        "    for val_year in unique_years:\n",
        "        train_years_mask = years_train < val_year\n",
        "        val_year_mask = years_train == val_year\n",
        "\n",
        "        X_train_cv = X_train[train_years_mask]\n",
        "        y_train_cv = y_train[train_years_mask]\n",
        "        X_val_cv = X_train[val_year_mask]\n",
        "        y_val_cv = y_train[val_year_mask]\n",
        "\n",
        "        if X_train_cv.empty or X_val_cv.empty:\n",
        "            continue\n",
        "\n",
        "        pipeline.fit(X_train_cv, y_train_cv)\n",
        "        y_pred_cv = pipeline.predict(X_val_cv)\n",
        "\n",
        "        mae_scores.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
        "        rmse_scores.append(\n",
        "            np.sqrt(mean_squared_error(y_val_cv, y_pred_cv))\n",
        "        )\n",
        "        smape_scores.append(\n",
        "            symmetric_mean_absolute_percentage_error(y_val_cv, y_pred_cv)\n",
        "        )\n",
        "        r2_scores.append(r2_score(y_val_cv, y_pred_cv))\n",
        "\n",
        "    validation_results['Leave-One-Year-Out'] = {\n",
        "        'MAE': np.mean(mae_scores),\n",
        "        'RMSE': np.mean(rmse_scores),\n",
        "        'SMAPE': np.mean(smape_scores),\n",
        "        'R2': np.mean(r2_scores)\n",
        "    }\n",
        "\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "smape_train = symmetric_mean_absolute_percentage_error(y_train, y_train_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "smape_test = symmetric_mean_absolute_percentage_error(y_test, y_test_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "delta_mae_train = abs(mae_train - mae_test)\n",
        "delta_rmse_train = abs(rmse_train - rmse_test)\n",
        "delta_smape_train = abs(smape_train - smape_test)\n",
        "delta_r2_train = abs(r2_train - r2_test)\n",
        "\n",
        "results_data = []\n",
        "\n",
        "\n",
        "results_data.append({\n",
        "    'Technique': 'Training Set',\n",
        "    'MAE': mae_train,\n",
        "    'RMSE': rmse_train,\n",
        "    'SMAPE': smape_train,\n",
        "    'R2': r2_train,\n",
        "    'Delta MAE': delta_mae_train,\n",
        "    'Delta RMSE': delta_rmse_train,\n",
        "    'Delta SMAPE': delta_smape_train,\n",
        "    'Delta R2': delta_r2_train,\n",
        "    'Precision MAE (%)': 0.0,\n",
        "    'Precision RMSE (%)': 0.0,\n",
        "    'Precision SMAPE (%)': 0.0,\n",
        "    'Precision R2 (%)': 0.0,\n",
        "    'Overall Precision (%)': 0.0\n",
        "})\n",
        "\n",
        "results_data.append({\n",
        "    'Technique': 'Test Set',\n",
        "    'MAE': mae_test,\n",
        "    'RMSE': rmse_test,\n",
        "    'SMAPE': smape_test,\n",
        "    'R2': r2_test,\n",
        "    'Delta MAE': 0.0,\n",
        "    'Delta RMSE': 0.0,\n",
        "    'Delta SMAPE': 0.0,\n",
        "    'Delta R2': 0.0,\n",
        "    'Precision MAE (%)': 100.0,\n",
        "    'Precision RMSE (%)': 100.0,\n",
        "    'Precision SMAPE (%)': 100.0,\n",
        "    'Precision R2 (%)': 100.0,\n",
        "    'Overall Precision (%)': 100.0\n",
        "})\n",
        "\n",
        "for method, metrics in validation_results.items():\n",
        "    mae_val = metrics['MAE']\n",
        "    rmse_val = metrics['RMSE']\n",
        "    smape_val = metrics['SMAPE']\n",
        "    r2_val = metrics.get('R2', None)\n",
        "\n",
        "    delta_mae = abs(mae_val - mae_test)\n",
        "    delta_rmse = abs(rmse_val - rmse_test)\n",
        "    delta_smape = abs(smape_val - smape_test)\n",
        "    delta_r2 = abs(r2_val - r2_test) if r2_val is not None else 'N/A'\n",
        "\n",
        "    precision_mae = (1 - (delta_mae / delta_mae_train)) * 100 if delta_mae_train != 0 else 0\n",
        "    precision_rmse = (1 - (delta_rmse / delta_rmse_train)) * 100 if delta_rmse_train != 0 else 0\n",
        "    precision_smape = (1 - (delta_smape / delta_smape_train)) * 100 if delta_smape_train != 0 else 0\n",
        "    if delta_r2_train != 0 and r2_val is not None:\n",
        "        precision_r2 = (1 - (delta_r2 / delta_r2_train)) * 100\n",
        "    else:\n",
        "        precision_r2 = 'N/A'\n",
        "\n",
        "    precision_values = [precision_mae, precision_rmse, precision_smape]\n",
        "    if isinstance(precision_r2, float):\n",
        "        precision_values.append(precision_r2)\n",
        "    overall_precision = np.mean([p for p in precision_values if isinstance(p, (int, float))])\n",
        "\n",
        "    result_entry = {\n",
        "        'Technique': method,\n",
        "        'MAE': mae_val,\n",
        "        'RMSE': rmse_val,\n",
        "        'SMAPE': smape_val,\n",
        "        'Delta MAE': delta_mae,\n",
        "        'Delta RMSE': delta_rmse,\n",
        "        'Delta SMAPE': delta_smape,\n",
        "        'Precision MAE (%)': precision_mae,\n",
        "        'Precision RMSE (%)': precision_rmse,\n",
        "        'Precision SMAPE (%)': precision_smape,\n",
        "        'Overall Precision (%)': overall_precision\n",
        "    }\n",
        "\n",
        "    if r2_val is not None:\n",
        "        result_entry['R2'] = r2_val\n",
        "        result_entry['Delta R2'] = delta_r2\n",
        "        result_entry['Precision R2 (%)'] = precision_r2\n",
        "    else:\n",
        "        result_entry['R2'] = 'N/A'\n",
        "        result_entry['Delta R2'] = 'N/A'\n",
        "        result_entry['Precision R2 (%)'] = 'N/A'\n",
        "\n",
        "    results_data.append(result_entry)\n",
        "\n",
        "\n",
        "results_table = pd.DataFrame(results_data)\n",
        "\n",
        "metrics_to_format = ['MAE', 'RMSE', 'SMAPE', 'Delta MAE', 'Delta RMSE', 'Delta SMAPE',\n",
        "                     'Precision MAE (%)', 'Precision RMSE (%)', 'Precision SMAPE (%)',\n",
        "                     'Overall Precision (%)']\n",
        "\n",
        "results_table_formatted = results_table.copy()\n",
        "results_table_formatted[metrics_to_format] = results_table_formatted[metrics_to_format].applymap(\n",
        "    lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else x\n",
        ")\n",
        "\n",
        "\n",
        "def format_r2(x):\n",
        "    if isinstance(x, float):\n",
        "        return f\"{x:.4f}\"\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "results_table_formatted['R2'] = results_table_formatted['R2'].apply(format_r2)\n",
        "results_table_formatted['Delta R2'] = results_table_formatted['Delta R2'].apply(format_r2)\n",
        "results_table_formatted['Precision R2 (%)'] = results_table_formatted['Precision R2 (%)'].apply(format_r2)\n",
        "\n",
        "print(\"\\nFormatted Results:\")\n",
        "print(results_table_formatted)"
      ],
      "metadata": {
        "id": "5Cy9jIRwUPMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pls', PLSRegression())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'pls__n_components': list(range(1, X_train.shape[1] + 1))\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Best number of components: {grid_search.best_params_['pls__n_components']}\")\n",
        "\n",
        "\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "\n",
        "results = results[['param_pls__n_components', 'mean_train_score', 'mean_test_score']]\n",
        "results['param_pls__n_components'] = results['param_pls__n_components'].astype(int)\n",
        "results.sort_values('param_pls__n_components', inplace=True)\n",
        "\n",
        "\n",
        "results['mean_train_mae'] = -results['mean_train_score']\n",
        "results['mean_test_mae'] = -results['mean_test_score']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(results['param_pls__n_components'], results['mean_train_mae'], label='Training MAE', marker='o')\n",
        "plt.plot(results['param_pls__n_components'], results['mean_test_mae'], label='Cross-Validation MAE', marker='s')\n",
        "plt.xlabel('Number of PLS Components')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.title('Validation Curve for PLSRegression')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "iTCA7XSoTFRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_table_formatted.to_csv('DenguePLSR_N.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('DenguePLSR_N.csv')"
      ],
      "metadata": {
        "id": "snaXotTlU0Jr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}