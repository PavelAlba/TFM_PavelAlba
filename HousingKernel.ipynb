{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install reverse_geocoder"
      ],
      "metadata": {
        "id": "opVIfyrZHJvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import reverse_geocoder as rg\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    ShuffleSplit,\n",
        "    KFold,\n",
        "    LeaveOneOut,\n",
        "    GridSearchCV\n",
        ")\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "file_path = '/content/housing.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(f'Number of rows before removing missing values: {df.shape[0]}')\n",
        "\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "print(f'Number of rows after removing missing values: {df.shape[0]}')\n",
        "\n",
        "\n",
        "print(f'Number of rows before outlier removal: {df.shape[0]}')\n",
        "\n",
        "\n",
        "def remove_outliers_iqr(df, exclude_columns=None):\n",
        "    if exclude_columns is None:\n",
        "        exclude_columns = []\n",
        "    df_clean = df.copy()\n",
        "    numeric_cols = df_clean.select_dtypes(include=['number']).columns.difference(exclude_columns)\n",
        "    for column in numeric_cols:\n",
        "        Q1 = df_clean[column].quantile(0.25)\n",
        "        Q3 = df_clean[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df_clean = df_clean[(df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)]\n",
        "    return df_clean\n",
        "\n",
        "\n",
        "df = remove_outliers_iqr(df)\n",
        "\n",
        "\n",
        "print(f'Number of rows after outlier removal: {df.shape[0]}')\n",
        "\n",
        "\n",
        "\n",
        "coordinates = list(zip(df['latitude'], df['longitude']))\n",
        "\n",
        "\n",
        "locations = rg.search(coordinates, mode=1)\n",
        "\n",
        "\n",
        "df['city'] = [location['name'] for location in locations]\n",
        "\n",
        "\n",
        "one_hot_transformer_ocean = (\"categorical_ocean_proximity\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"ocean_proximity\"])\n",
        "one_hot_transformer_city = (\"categorical_city\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"city\"])\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        one_hot_transformer_ocean,\n",
        "        one_hot_transformer_city\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "\n",
        "transformed_df = preprocessor.fit_transform(df)\n",
        "\n",
        "\n",
        "ocean_feature_names = preprocessor.named_transformers_['categorical_ocean_proximity'].get_feature_names_out(['ocean_proximity'])\n",
        "city_feature_names = preprocessor.named_transformers_['categorical_city'].get_feature_names_out(['city'])\n",
        "remainder_features = [col for col in df.columns if col not in ['ocean_proximity', 'city']]\n",
        "\n",
        "all_feature_names = list(ocean_feature_names) + list(city_feature_names) + remainder_features\n",
        "\n",
        "\n",
        "transformed_df = pd.DataFrame(transformed_df, columns=all_feature_names)\n",
        "transformed_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "columns_to_exclude = ['median_house_value', 'longitude', 'latitude', 'city']\n",
        "X = transformed_df.drop(columns=columns_to_exclude, errors='ignore')\n",
        "y = transformed_df['median_house_value']\n",
        "cities = df['city']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "U9UIz5WtxFbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'kernelridge__alpha': [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
        "    'kernelridge__gamma': np.logspace(-3, 3, 7)\n",
        "}\n",
        "\n",
        "\n",
        "pipeline = make_pipeline(StandardScaler(), KernelRidge(kernel='rbf'))\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_alpha = grid_search.best_params_['kernelridge__alpha']\n",
        "best_gamma = grid_search.best_params_['kernelridge__gamma']\n",
        "print(f\"Best parameters: alpha={best_alpha}, gamma={best_gamma}\")"
      ],
      "metadata": {
        "id": "G8Q49pl7xVEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(StandardScaler(), KernelRidge(kernel='rbf',alpha=0.1,gamma=0.001))\n",
        "\n",
        "validation_results = {}\n",
        "\n",
        "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    numerator = np.abs(y_true - y_pred)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    epsilon = 1e-10\n",
        "    denominator = np.where(denominator == 0, epsilon, denominator)\n",
        "    return np.mean(numerator / denominator) * 100\n",
        "\n",
        "def compute_metrics(model, X, y, cv, compute_r2=True):\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "    smape_scores = []\n",
        "    if compute_r2:\n",
        "        r2_scores = []\n",
        "\n",
        "    for train_index, val_index in cv.split(X):\n",
        "        X_train_cv, X_val_cv = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        model.fit(X_train_cv, y_train_cv)\n",
        "        y_pred_cv = model.predict(X_val_cv)\n",
        "\n",
        "        mae_scores.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
        "        rmse_scores.append(\n",
        "            np.sqrt(mean_squared_error(y_val_cv, y_pred_cv))\n",
        "        )\n",
        "        smape_scores.append(\n",
        "            symmetric_mean_absolute_percentage_error(y_val_cv, y_pred_cv)\n",
        "        )\n",
        "        if compute_r2:\n",
        "            r2_scores.append(r2_score(y_val_cv, y_pred_cv))\n",
        "\n",
        "    metrics = {\n",
        "        'MAE': np.mean(mae_scores),\n",
        "        'RMSE': np.mean(rmse_scores),\n",
        "        'SMAPE': np.mean(smape_scores)\n",
        "    }\n",
        "    if compute_r2:\n",
        "        metrics['R2'] = np.mean(r2_scores)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "random_cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        "scores = compute_metrics(pipeline, X_train, y_train, random_cv)\n",
        "validation_results['Random CV (5 splits)'] = scores\n",
        "\n",
        "# Random Cross-Validation (ShuffleSplit with 10 splits)\n",
        "random_cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
        "scores = compute_metrics(pipeline, X_train, y_train, random_cv)\n",
        "validation_results['Random CV (10 splits)'] = scores\n",
        "\n",
        "# 2. K-Fold Cross-Validation with various folds (Shuffled)\n",
        "for n_splits in [5, 7, 10]:\n",
        "    kfold_shuffle_cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    scores = compute_metrics(pipeline, X_train, y_train, kfold_shuffle_cv)\n",
        "    validation_results[f'K-Fold ({n_splits} folds, shuffled)'] = scores\n",
        "\n",
        "\n",
        "\n",
        "# 4. Venetian Blinds Cross-Validation\n",
        "num_partitions = 10\n",
        "indices = np.arange(len(X_train))\n",
        "venetian_mae_scores = []\n",
        "venetian_rmse_scores = []\n",
        "venetian_smape_scores = []\n",
        "venetian_r2_scores = []\n",
        "\n",
        "for i in range(num_partitions):\n",
        "    test_mask_vb = indices % num_partitions == i\n",
        "    train_mask_vb = ~test_mask_vb\n",
        "\n",
        "    X_train_vb = X_train.iloc[train_mask_vb]\n",
        "    X_val_vb = X_train.iloc[test_mask_vb]\n",
        "    y_train_vb = y_train.iloc[train_mask_vb]\n",
        "    y_val_vb = y_train.iloc[test_mask_vb]\n",
        "\n",
        "    pipeline.fit(X_train_vb, y_train_vb)\n",
        "    y_pred_vb = pipeline.predict(X_val_vb)\n",
        "\n",
        "    venetian_mae_scores.append(mean_absolute_error(y_val_vb, y_pred_vb))\n",
        "    venetian_rmse_scores.append(\n",
        "        np.sqrt(mean_squared_error(y_val_vb, y_pred_vb))\n",
        "    )\n",
        "    venetian_smape_scores.append(\n",
        "        symmetric_mean_absolute_percentage_error(y_val_vb, y_pred_vb)\n",
        "    )\n",
        "    venetian_r2_scores.append(r2_score(y_val_vb, y_pred_vb))\n",
        "\n",
        "validation_results['Venetian Blinds'] = {\n",
        "    'MAE': np.mean(venetian_mae_scores),\n",
        "    'RMSE': np.mean(venetian_rmse_scores),\n",
        "    'SMAPE': np.mean(venetian_smape_scores),\n",
        "    'R2': np.mean(venetian_r2_scores)\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "smape_train = symmetric_mean_absolute_percentage_error(y_train, y_train_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "smape_test = symmetric_mean_absolute_percentage_error(y_test, y_test_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "delta_mae_train = abs(mae_train - mae_test)\n",
        "delta_rmse_train = abs(rmse_train - rmse_test)\n",
        "delta_smape_train = abs(smape_train - smape_test)\n",
        "delta_r2_train = abs(r2_train - r2_test)\n",
        "\n",
        "\n",
        "results_data = []\n",
        "\n",
        "\n",
        "results_data.append({\n",
        "    'Technique': 'Training Set',\n",
        "    'MAE': mae_train,\n",
        "    'RMSE': rmse_train,\n",
        "    'SMAPE': smape_train,\n",
        "    'R2': r2_train,\n",
        "    'Delta MAE': delta_mae_train,\n",
        "    'Delta RMSE': delta_rmse_train,\n",
        "    'Delta SMAPE': delta_smape_train,\n",
        "    'Delta R2': delta_r2_train,\n",
        "    'Precision MAE (%)': 0.0,\n",
        "    'Precision RMSE (%)': 0.0,\n",
        "    'Precision SMAPE (%)': 0.0,\n",
        "    'Precision R2 (%)': 0.0,\n",
        "    'Overall Precision (%)': 0.0\n",
        "})\n",
        "\n",
        "\n",
        "results_data.append({\n",
        "    'Technique': 'Test Set',\n",
        "    'MAE': mae_test,\n",
        "    'RMSE': rmse_test,\n",
        "    'SMAPE': smape_test,\n",
        "    'R2': r2_test,\n",
        "    'Delta MAE': 0.0,\n",
        "    'Delta RMSE': 0.0,\n",
        "    'Delta SMAPE': 0.0,\n",
        "    'Delta R2': 0.0,\n",
        "    'Precision MAE (%)': 100.0,\n",
        "    'Precision RMSE (%)': 100.0,\n",
        "    'Precision SMAPE (%)': 100.0,\n",
        "    'Precision R2 (%)': 100.0,\n",
        "    'Overall Precision (%)': 100.0\n",
        "})\n",
        "\n",
        "\n",
        "for method, metrics in validation_results.items():\n",
        "    mae_val = metrics['MAE']\n",
        "    rmse_val = metrics['RMSE']\n",
        "    smape_val = metrics['SMAPE']\n",
        "    r2_val = metrics.get('R2', None)\n",
        "\n",
        "    delta_mae = abs(mae_val - mae_test)\n",
        "    delta_rmse = abs(rmse_val - rmse_test)\n",
        "    delta_smape = abs(smape_val - smape_test)\n",
        "    delta_r2 = abs(r2_val - r2_test) if r2_val is not None else 'N/A'\n",
        "\n",
        "    precision_mae = (1 - (delta_mae / delta_mae_train)) * 100 if delta_mae_train != 0 else 0\n",
        "    precision_rmse = (1 - (delta_rmse / delta_rmse_train)) * 100 if delta_rmse_train != 0 else 0\n",
        "    precision_smape = (1 - (delta_smape / delta_smape_train)) * 100 if delta_smape_train != 0 else 0\n",
        "    if delta_r2_train != 0 and r2_val is not None:\n",
        "        precision_r2 = (1 - (delta_r2 / delta_r2_train)) * 100\n",
        "    else:\n",
        "        precision_r2 = 'N/A'\n",
        "\n",
        "    precision_values = [precision_mae, precision_rmse, precision_smape]\n",
        "    if isinstance(precision_r2, float):\n",
        "        precision_values.append(precision_r2)\n",
        "    overall_precision = np.mean([p for p in precision_values if isinstance(p, (int, float))])\n",
        "\n",
        "    result_entry = {\n",
        "        'Technique': method,\n",
        "        'MAE': mae_val,\n",
        "        'RMSE': rmse_val,\n",
        "        'SMAPE': smape_val,\n",
        "        'Delta MAE': delta_mae,\n",
        "        'Delta RMSE': delta_rmse,\n",
        "        'Delta SMAPE': delta_smape,\n",
        "        'Precision MAE (%)': precision_mae,\n",
        "        'Precision RMSE (%)': precision_rmse,\n",
        "        'Precision SMAPE (%)': precision_smape,\n",
        "        'Overall Precision (%)': overall_precision\n",
        "    }\n",
        "\n",
        "    if r2_val is not None:\n",
        "        result_entry['R2'] = r2_val\n",
        "        result_entry['Delta R2'] = delta_r2\n",
        "        result_entry['Precision R2 (%)'] = precision_r2\n",
        "    else:\n",
        "        result_entry['R2'] = 'N/A'\n",
        "        result_entry['Delta R2'] = 'N/A'\n",
        "        result_entry['Precision R2 (%)'] = 'N/A'\n",
        "\n",
        "    results_data.append(result_entry)\n",
        "\n",
        "\n",
        "results_table = pd.DataFrame(results_data)\n",
        "\n",
        "\n",
        "metrics_to_format = ['MAE', 'RMSE', 'SMAPE', 'Delta MAE', 'Delta RMSE', 'Delta SMAPE',\n",
        "                     'Precision MAE (%)', 'Precision RMSE (%)', 'Precision SMAPE (%)',\n",
        "                     'Overall Precision (%)']\n",
        "\n",
        "results_table_formatted = results_table.copy()\n",
        "results_table_formatted[metrics_to_format] = results_table_formatted[metrics_to_format].applymap(\n",
        "    lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else x\n",
        ")\n",
        "\n",
        "\n",
        "def format_r2(x):\n",
        "    if isinstance(x, float):\n",
        "        return f\"{x:.4f}\"\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "results_table_formatted['R2'] = results_table_formatted['R2'].apply(format_r2)\n",
        "results_table_formatted['Delta R2'] = results_table_formatted['Delta R2'].apply(format_r2)\n",
        "results_table_formatted['Precision R2 (%)'] = results_table_formatted['Precision R2 (%)'].apply(format_r2)\n",
        "\n",
        "print(\"\\nFormatted Results:\")\n",
        "print(results_table_formatted)"
      ],
      "metadata": {
        "id": "k81ck8BTzZo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_table_formatted.to_csv('HousingKernel_N.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('HousingKernel_N.csv')"
      ],
      "metadata": {
        "id": "487PnVqi0fit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}