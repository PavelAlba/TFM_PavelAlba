{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XqFWq460FV8r"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    ShuffleSplit,\n",
        "    KFold,\n",
        "    LeaveOneOut\n",
        ")\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "file_path = '/content/winequality-white.csv'\n",
        "df = pd.read_csv(file_path, sep=';')\n",
        "\n",
        "\n",
        "print(f'Number of rows before removing missing values: {df.shape[0]}')\n",
        "\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "print(f'Number of rows after removing missing values: {df.shape[0]}')\n",
        "\n",
        "\n",
        "print(f'Number of rows before outlier removal: {df.shape[0]}')\n",
        "\n",
        "\n",
        "def remove_outliers_iqr(df, exclude_columns=None):\n",
        "    if exclude_columns is None:\n",
        "        exclude_columns = []\n",
        "    df_clean = df.copy()\n",
        "    numeric_cols = df_clean.select_dtypes(include=['number']).columns.difference(exclude_columns)\n",
        "    for column in numeric_cols:\n",
        "        Q1 = df_clean[column].quantile(0.25)\n",
        "        Q3 = df_clean[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df_clean = df_clean[(df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)]\n",
        "    return df_clean\n",
        "\n",
        "\n",
        "df = remove_outliers_iqr(df)\n",
        "\n",
        "\n",
        "print(f'Number of rows after outlier removal: {df.shape[0]}')\n",
        "\n",
        "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    numerator = np.abs(y_true - y_pred)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    epsilon = 1e-10\n",
        "    denominator = np.where(denominator == 0, epsilon, denominator)\n",
        "    return np.mean(numerator / denominator) * 100\n",
        "\n",
        "\n",
        "X = df.drop(columns=['quality'])\n",
        "y = df['quality']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "pipeline = make_pipeline(StandardScaler(), PLSRegression(n_components=9))\n",
        "\n",
        "\n",
        "validation_results = {}\n",
        "\n",
        "\n",
        "def compute_metrics(model, X, y, cv, compute_r2=True):\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "    smape_scores = []\n",
        "    if compute_r2:\n",
        "        r2_scores = []\n",
        "\n",
        "    for train_index, val_index in cv.split(X):\n",
        "        X_train_cv, X_val_cv = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        model.fit(X_train_cv, y_train_cv)\n",
        "        y_pred_cv = model.predict(X_val_cv)\n",
        "\n",
        "        mae_scores.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
        "        rmse_scores.append(\n",
        "            np.sqrt(mean_squared_error(y_val_cv, y_pred_cv))\n",
        "        )\n",
        "        smape_scores.append(\n",
        "            symmetric_mean_absolute_percentage_error(y_val_cv, y_pred_cv)\n",
        "        )\n",
        "        if compute_r2:\n",
        "            r2_scores.append(r2_score(y_val_cv, y_pred_cv))\n",
        "\n",
        "    metrics = {\n",
        "        'MAE': np.mean(mae_scores),\n",
        "        'RMSE': np.mean(rmse_scores),\n",
        "        'SMAPE': np.mean(smape_scores)\n",
        "    }\n",
        "    if compute_r2:\n",
        "        metrics['R2'] = np.mean(r2_scores)\n",
        "    return metrics\n",
        "\n",
        "# 1. Random Cross-Validation (ShuffleSplit with 5 splits)\n",
        "random_cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        "scores = compute_metrics(pipeline, X_train, y_train, random_cv)\n",
        "validation_results['Random CV (5 splits)'] = scores\n",
        "\n",
        "# Random Cross-Validation (ShuffleSplit with 10 splits)\n",
        "random_cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
        "scores = compute_metrics(pipeline, X_train, y_train, random_cv)\n",
        "validation_results['Random CV (10 splits)'] = scores\n",
        "\n",
        "# 2. K-Fold Cross-Validation with various folds (Shuffled)\n",
        "for n_splits in [5, 7, 10]:\n",
        "    kfold_shuffle_cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    scores = compute_metrics(pipeline, X_train, y_train, kfold_shuffle_cv)\n",
        "    validation_results[f'K-Fold ({n_splits} folds, shuffled)'] = scores\n",
        "\n",
        "# 3. Leave-One-Out Cross-Validation (LOO)\n",
        "loo_cv = LeaveOneOut()\n",
        "scores = compute_metrics(pipeline, X_train, y_train, loo_cv, compute_r2=False)\n",
        "validation_results['Leave-One-Out'] = scores\n",
        "\n",
        "# 4. Venetian Blinds Cross-Validation\n",
        "num_partitions = 10\n",
        "indices = np.arange(len(X_train))\n",
        "venetian_mae_scores = []\n",
        "venetian_rmse_scores = []\n",
        "venetian_smape_scores = []\n",
        "venetian_r2_scores = []\n",
        "\n",
        "for i in range(num_partitions):\n",
        "    test_mask_vb = indices % num_partitions == i\n",
        "    train_mask_vb = ~test_mask_vb\n",
        "\n",
        "    X_train_vb = X_train.iloc[train_mask_vb]\n",
        "    X_val_vb = X_train.iloc[test_mask_vb]\n",
        "    y_train_vb = y_train.iloc[train_mask_vb]\n",
        "    y_val_vb = y_train.iloc[test_mask_vb]\n",
        "\n",
        "    pipeline.fit(X_train_vb, y_train_vb)\n",
        "    y_pred_vb = pipeline.predict(X_val_vb)\n",
        "\n",
        "    venetian_mae_scores.append(mean_absolute_error(y_val_vb, y_pred_vb))\n",
        "    venetian_rmse_scores.append(\n",
        "        np.sqrt(mean_squared_error(y_val_vb, y_pred_vb))\n",
        "    )\n",
        "    venetian_smape_scores.append(\n",
        "        symmetric_mean_absolute_percentage_error(y_val_vb, y_pred_vb)\n",
        "    )\n",
        "    venetian_r2_scores.append(r2_score(y_val_vb, y_pred_vb))\n",
        "\n",
        "validation_results['Venetian Blinds'] = {\n",
        "    'MAE': np.mean(venetian_mae_scores),\n",
        "    'RMSE': np.mean(venetian_rmse_scores),\n",
        "    'SMAPE': np.mean(venetian_smape_scores),\n",
        "    'R2': np.mean(venetian_r2_scores)\n",
        "}\n",
        "\n",
        "# 5. K-Fold Cross-Validation with 7 Folds (No Shuffling)\n",
        "kfold_cv = KFold(n_splits=7, shuffle=False)\n",
        "scores = compute_metrics(pipeline, X_train, y_train, kfold_cv)\n",
        "validation_results['K-Fold (7 folds, no shuffle)'] = scores\n",
        "\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "smape_train = symmetric_mean_absolute_percentage_error(y_train, y_train_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "smape_test = symmetric_mean_absolute_percentage_error(y_test, y_test_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "delta_mae_train = abs(mae_train - mae_test)\n",
        "delta_rmse_train = abs(rmse_train - rmse_test)\n",
        "delta_smape_train = abs(smape_train - smape_test)\n",
        "delta_r2_train = abs(r2_train - r2_test)\n",
        "\n",
        "\n",
        "results_data = []\n",
        "\n",
        "results_data.append({\n",
        "    'Technique': 'Training Set',\n",
        "    'MAE': mae_train,\n",
        "    'RMSE': rmse_train,\n",
        "    'SMAPE': smape_train,\n",
        "    'R2': r2_train,\n",
        "    'Delta MAE': delta_mae_train,\n",
        "    'Delta RMSE': delta_rmse_train,\n",
        "    'Delta SMAPE': delta_smape_train,\n",
        "    'Delta R2': delta_r2_train,\n",
        "    'Precision MAE (%)': 0.0,\n",
        "    'Precision RMSE (%)': 0.0,\n",
        "    'Precision SMAPE (%)': 0.0,\n",
        "    'Precision R2 (%)': 0.0,\n",
        "    'Overall Precision (%)': 0.0\n",
        "})\n",
        "\n",
        "results_data.append({\n",
        "    'Technique': 'Test Set',\n",
        "    'MAE': mae_test,\n",
        "    'RMSE': rmse_test,\n",
        "    'SMAPE': smape_test,\n",
        "    'R2': r2_test,\n",
        "    'Delta MAE': 0.0,\n",
        "    'Delta RMSE': 0.0,\n",
        "    'Delta SMAPE': 0.0,\n",
        "    'Delta R2': 0.0,\n",
        "    'Precision MAE (%)': 100.0,\n",
        "    'Precision RMSE (%)': 100.0,\n",
        "    'Precision SMAPE (%)': 100.0,\n",
        "    'Precision R2 (%)': 100.0,\n",
        "    'Overall Precision (%)': 100.0\n",
        "})\n",
        "\n",
        "\n",
        "for method, metrics in validation_results.items():\n",
        "    mae_val = metrics['MAE']\n",
        "    rmse_val = metrics['RMSE']\n",
        "    smape_val = metrics['SMAPE']\n",
        "    r2_val = metrics.get('R2', None)\n",
        "\n",
        "    delta_mae = abs(mae_val - mae_test)\n",
        "    delta_rmse = abs(rmse_val - rmse_test)\n",
        "    delta_smape = abs(smape_val - smape_test)\n",
        "    delta_r2 = abs(r2_val - r2_test) if r2_val is not None else 'N/A'\n",
        "\n",
        "    precision_mae = (1 - (delta_mae / delta_mae_train)) * 100 if delta_mae_train != 0 else 0\n",
        "    precision_rmse = (1 - (delta_rmse / delta_rmse_train)) * 100 if delta_rmse_train != 0 else 0\n",
        "    precision_smape = (1 - (delta_smape / delta_smape_train)) * 100 if delta_smape_train != 0 else 0\n",
        "    if delta_r2_train != 0 and r2_val is not None:\n",
        "        precision_r2 = (1 - (delta_r2 / delta_r2_train)) * 100\n",
        "    else:\n",
        "        precision_r2 = 'N/A'\n",
        "\n",
        "    precision_values = [precision_mae, precision_rmse, precision_smape]\n",
        "    if isinstance(precision_r2, float):\n",
        "        precision_values.append(precision_r2)\n",
        "    overall_precision = np.mean([p for p in precision_values if isinstance(p, (int, float))])\n",
        "\n",
        "    result_entry = {\n",
        "        'Technique': method,\n",
        "        'MAE': mae_val,\n",
        "        'RMSE': rmse_val,\n",
        "        'SMAPE': smape_val,\n",
        "        'Delta MAE': delta_mae,\n",
        "        'Delta RMSE': delta_rmse,\n",
        "        'Delta SMAPE': delta_smape,\n",
        "        'Precision MAE (%)': precision_mae,\n",
        "        'Precision RMSE (%)': precision_rmse,\n",
        "        'Precision SMAPE (%)': precision_smape,\n",
        "        'Overall Precision (%)': overall_precision\n",
        "    }\n",
        "\n",
        "    if r2_val is not None:\n",
        "        result_entry['R2'] = r2_val\n",
        "        result_entry['Delta R2'] = delta_r2\n",
        "        result_entry['Precision R2 (%)'] = precision_r2\n",
        "    else:\n",
        "        result_entry['R2'] = 'N/A'\n",
        "        result_entry['Delta R2'] = 'N/A'\n",
        "        result_entry['Precision R2 (%)'] = 'N/A'\n",
        "\n",
        "    results_data.append(result_entry)\n",
        "\n",
        "results_table = pd.DataFrame(results_data)\n",
        "\n",
        "metrics_to_format = ['MAE', 'RMSE', 'SMAPE', 'Delta MAE', 'Delta RMSE', 'Delta SMAPE',\n",
        "                     'Precision MAE (%)', 'Precision RMSE (%)', 'Precision SMAPE (%)',\n",
        "                     'Overall Precision (%)']\n",
        "\n",
        "results_table_formatted = results_table.copy()\n",
        "results_table_formatted[metrics_to_format] = results_table_formatted[metrics_to_format].applymap(\n",
        "    lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else x\n",
        ")\n",
        "\n",
        "def format_r2(x):\n",
        "    if isinstance(x, float):\n",
        "        return f\"{x:.4f}\"\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "results_table_formatted['R2'] = results_table_formatted['R2'].apply(format_r2)\n",
        "results_table_formatted['Delta R2'] = results_table_formatted['Delta R2'].apply(format_r2)\n",
        "results_table_formatted['Precision R2 (%)'] = results_table_formatted['Precision R2 (%)'].apply(format_r2)\n",
        "\n",
        "print(\"\\nFormatted Results:\")\n",
        "print(results_table_formatted)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLJeUsGvPEd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'plsregression__n_components': list(range(1, X_train.shape[1] + 1))\n",
        "}\n",
        "\n",
        "\n",
        "pipeline = make_pipeline(StandardScaler(), PLSRegression())\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=10,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Best number of components: {grid_search.best_params_['plsregression__n_components']}\")\n",
        "\n",
        "\n",
        "mean_test_scores = -grid_search.cv_results_['mean_test_score']\n",
        "mean_train_scores = -grid_search.cv_results_['mean_train_score']\n",
        "n_components = param_grid['plsregression__n_components']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(n_components, mean_train_scores, label='Training MAE', marker='o')\n",
        "plt.plot(n_components, mean_test_scores, label='Cross-Validation MAE', marker='s')\n",
        "plt.xlabel('Number of PLS Components')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.title('Validation Curve for PLSRegression')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_eVL1AcSxC9"
      },
      "outputs": [],
      "source": [
        "results_table_formatted.to_csv('WinePLSR_N.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('WinePLSR_N.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSYSa7GzgMZ6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}